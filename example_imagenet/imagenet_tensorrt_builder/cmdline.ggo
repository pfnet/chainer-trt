# Copyright (c) 2018 Preferred Networks, Inc. All rights reserved.

package "imagenet_tensorrt_builder"
version "0.1"

option "dir"        i "path to directory name contains model json and weights exported by dump_chainer.py or dump_caffe.py" string typestr="filename" yes
option "gpu"        g "GPU ID" int default="0" no
option "model"      o "specify where to save the built model" string typestr="filename" yes
option "mode"       m "specify mode" values="fp32","fp16","int8" default="fp32" no
option "calib"      c "specify filename of calibration image list if using mode=int8 and do calibration from scratch" string typestr="filename" no
option "in-cache"   - "specify filename to calibration cache when using mode=int8" string typestr="filename" no
option "out-cache"  - "specify output filename to calibration cache if using mode=int8 (--calib also needs to be specified)" string typestr="filename" default="" no
option "max-batch"  b "specify the maximum batch size this model is supposed to receive" int typestr="batch-size" default="1" no
option "workspace"  w "specify workspace size in GB that TensorRT is allowed to use while building the network" int typestr="GB" default="4" no
option "dla"        - "specify when you want to use DLA (Need '--mode fp16' together)" flag off
option "verbose"    v "Verbose mode" no

